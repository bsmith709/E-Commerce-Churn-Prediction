{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8dc517",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Olist Ecommerce Dataset\n",
    "This notebook will explore the Olist Ecommerce Dataset to identify key characteristics useful for predicting customer churn.\n",
    "\n",
    "First, import libraries and configure dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b2d7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "DATA_DIR = 'archive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97054650",
   "metadata": {},
   "source": [
    "Load each dataset as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba1af026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\n",
    "try:\n",
    "    customers_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_customers_dataset.csv'))\n",
    "    orders_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_orders_dataset.csv'))\n",
    "    order_items_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_order_items_dataset.csv'))\n",
    "    order_payments_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_order_payments_dataset.csv'))\n",
    "    # product_info needs joining orders->items->products later\n",
    "    products_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_products_dataset.csv'))\n",
    "    # reviews might be useful for features later\n",
    "    reviews_df = pd.read_csv(os.path.join(DATA_DIR, 'olist_order_reviews_dataset.csv'))\n",
    "\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    print(f\"Please ensure the CSV files are in the '{DATA_DIR}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99632840",
   "metadata": {},
   "source": [
    "Get a first look at each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41db3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting: Customers DataFrame ---\n",
      "Shape: (99441, 5)\n",
      "\n",
      "First 5 rows:\n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspecting: Orders DataFrame ---\n",
      "Shape: (99441, 8)\n",
      "\n",
      "First 5 rows:\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspecting: Order Items DataFrame ---\n",
      "Shape: (112650, 7)\n",
      "\n",
      "First 5 rows:\n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspecting: Order Payments DataFrame ---\n",
      "Shape: (103886, 5)\n",
      "\n",
      "First 5 rows:\n",
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspecting: Products DataFrame ---\n",
      "Shape: (32951, 9)\n",
      "\n",
      "First 5 rows:\n",
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_length  product_description_length  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_length         32341 non-null  float64\n",
      " 3   product_description_length  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspecting: Reviews DataFrame ---\n",
      "Shape: (99224, 7)\n",
      "\n",
      "First 5 rows:\n",
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4                  NaN   \n",
      "1             5                  NaN   \n",
      "2             5                  NaN   \n",
      "3             5                  NaN   \n",
      "4             5                  NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                                NaN  2018-01-18 00:00:00   \n",
      "1                                                NaN  2018-03-10 00:00:00   \n",
      "2                                                NaN  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n",
      "\n",
      "Info (Data Types & Non-Null Counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   review_id                99224 non-null  object\n",
      " 1   order_id                 99224 non-null  object\n",
      " 2   review_score             99224 non-null  int64 \n",
      " 3   review_comment_title     11568 non-null  object\n",
      " 4   review_comment_message   40977 non-null  object\n",
      " 5   review_creation_date     99224 non-null  object\n",
      " 6   review_answer_timestamp  99224 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Customers\": customers_df,\n",
    "    \"Orders\": orders_df,\n",
    "    \"Order Items\": order_items_df,\n",
    "    \"Order Payments\": order_payments_df,\n",
    "    \"Products\": products_df,\n",
    "    \"Reviews\": reviews_df\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n--- Inspecting: {name} DataFrame ---\")\n",
    "    print(f\"Shape: {df.shape}\") # (rows, columns)\n",
    "\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    # Display more columns if needed: pd.set_option('display.max_columns', None)\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nInfo (Data Types & Non-Null Counts):\")\n",
    "    # This is crucial for spotting missing values and wrong data types\n",
    "    df.info()\n",
    "\n",
    "    # Get basic statistics for numerical columns, only if they exist\n",
    "    #print(\"\\nDescriptive Statistics (Numerical Columns):\")\n",
    "    #numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "    #if not numerical_cols.empty:\n",
    "    #    print(df.describe(include=[np.number])) # Use include=[np.number] to only show numerical stats initially\n",
    "    #else:\n",
    "    #    print(\"No numerical columns found in this DataFrame.\")\n",
    "\n",
    "\n",
    "    # Optional: Look at categorical descriptions if needed later\n",
    "    # print(\"\\nDescriptive Statistics (Categorical Columns):\")\n",
    "    # print(df.describe(include=['object']))\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89670ad",
   "metadata": {},
   "source": [
    "### Most Important Features Identified\n",
    "- #### Recency: Days since customers last purchase\n",
    "    - **Reasoning:**  Customers who haven't bought in a long time are likely to have churned\n",
    "    - **Extraction:** Max of order_purchase_timestamp\n",
    "- #### Frequency: Total number of orders a customer has placed\n",
    "    - **Reasoning:** Customers who buy often are more engaged, less likely to churn\n",
    "    - **Extraction:** Count unique order_ids associated with customer\n",
    "- #### Tenure: Days since customers first purchase\n",
    "    - **Reasoning:** Helps identify low-risk, loyal customers that are less likely to churn\n",
    "    - **Extraction:** Days since first order date associated with customer\n",
    "- #### Monetary: Total amount of money customer has spent\n",
    "    - **Reasoning:** High-spenders are valuable, and their spending habit is a strong engagement signal\n",
    "    - **Extraction:** Sum of all order payment values associated with customer\n",
    "- #### Average Payment Installments\n",
    "    - **Reasoning:** Customers who pay in many installments likely place high value orders and experience different churn patterns\n",
    "    - **Extraction:** Average of all payment installment amounts for orders associated with customer\n",
    "- #### Preferred Payment Method\n",
    "    - **Reasoning:** Customers may have different curn patterns based on preferred payment type\n",
    "    - **Extraction:** Mode of all payment_type associated with customer\n",
    "- #### Average Payment Complexity: Unique payment methods per single order\n",
    "    - **Reasoning:** Customers who use multiple payment methods per order likely wait for vouchers and have a different churn profile\n",
    "    - **Extraction:** Average of the max payment_sequential for each order associated with a customer\n",
    "- #### Average Review Score\n",
    "    - **Reasoning:** Customers who leave high reviews are more satisfied, less likely to churn\n",
    "    - **Extraction:** Average of all reviews associated with customer\n",
    "- #### Review Engagement Rate: How often does customer leave review messages\n",
    "    - **Reasoning:** A customer who leaves review messages, good or bad, is more engaged and less likely to churn\n",
    "    - **Extraction:** The ratio of orders with messages vs orders without messages for orders associated wtih customer\n",
    "- #### Average Shipping Cost\n",
    "    - **Reasoning:** Customers who pay more for shipping are more likely to churn\n",
    "    - **Extraction:** Take the average sum of freight_value for every order item for orders associated with customer\n",
    "- #### Number of Unique Product Categories Purchased\n",
    "    - **Reasoning:** Customers who have bought products from more categories are more invested in the platform, less likely to churn\n",
    "    - **Extraction:** Number of unique product categories associated with customer orders\n",
    "- #### Number of Unique Sellers Purchased From\n",
    "    - **Reasoning:** Customers who purchase form many sellers are more engaged, less likely to churn\n",
    "    - **Extraction:** Total of unique seller_id for orders items associated with customer\n",
    "- #### Average Payment Approval Time: Gap between order placement and approval\n",
    "    - **Reasoning:** Customers who frequently experience delays between placing orders and order approval are more likely to churn\n",
    "    - **Extraction:** Average difference between order approval and order placement\n",
    "- #### Average Delivery vs Estimate\n",
    "    - **Reasoning:** Customers who consistently get late packages are likely to churn\n",
    "    - **Extraction:** Average time between order_delivered_customer_date and order_estimated_delivery_date\n",
    "- #### Average Carrier Transit Time\n",
    "    - **Reasoning:** Customers who experience long shipping times are more likely to churn\n",
    "    - **Extraction:** Average difference between carier delivery and customer delivery of all orders associated with a customer\n",
    "- #### Average Time Between Seller Shipping Deadline and Carrier Delivery\n",
    "    - **Reasoning:** Sellers not meeting their fulfillment deadlines will make customers more liekly to churn\n",
    "    - **Extraction:** Average difference between seller deadline and carrier delivery for orders associated with customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed68a42",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "- The previous output shows that dates are stored as strings, they will need to be converted to datetime objects. \n",
    "- There are some missing orders that will need filtered out. \n",
    "- Products with missing categories will need to have their categories set to 'unknown'. \n",
    "- Can remove customer_zip_code_prefix, customer_city, customer_state, order_item_id, review_id, review_comment_title, all product columns except product_id and product_category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "675591fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (99441, 8)\n",
      "\n",
      "'order_status' counts:\n",
      "order_status\n",
      "delivered      96478\n",
      "shipped         1107\n",
      "canceled         625\n",
      "unavailable      609\n",
      "invoiced         314\n",
      "processing       301\n",
      "created            5\n",
      "approved           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered for 'delivered' status. New shape: (96478, 8)\n",
      "\n",
      "Converting timestamp columns...\n",
      "\n",
      "Verifying 'cleaned_orders_minimal' Dtypes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 96478 entries, 0 to 99440\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       96478 non-null  object        \n",
      " 1   customer_id                    96478 non-null  object        \n",
      " 2   order_purchase_timestamp       96478 non-null  datetime64[ns]\n",
      " 3   order_approved_at              96464 non-null  datetime64[ns]\n",
      " 4   order_delivered_carrier_date   96476 non-null  datetime64[ns]\n",
      " 5   order_delivered_customer_date  96470 non-null  datetime64[ns]\n",
      " 6   order_estimated_delivery_date  96478 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), object(2)\n",
      "memory usage: 5.9+ MB\n",
      "\n",
      "Successfully saved cleaned minimal orders data to: archive/cleaned_orders_minimal.csv\n",
      "\n",
      "--- Processing: Reviews DataFrame ---\n",
      "Original shape: (99224, 7)\n",
      "Converting timestamp columns...\n",
      "\n",
      "Verifying 'cleaned_reviewes_minimal' Dtypes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   order_id                99224 non-null  object\n",
      " 1   review_score            99224 non-null  int64 \n",
      " 2   review_comment_message  40977 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "Successfully saved cleaned minimal reviews data to: archive/cleaned_reviews_minimal.csv\n",
      "\n",
      "--- Processing: Order Items DataFrame ---\n",
      "Original shape: (112650, 7)\n",
      "Converting 'shipping_limit_date' to datetime object...\n",
      "\n",
      "Verifying 'cleaned_order_items_minimal' Dtypes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   order_id             112650 non-null  object        \n",
      " 1   product_id           112650 non-null  object        \n",
      " 2   seller_id            112650 non-null  object        \n",
      " 3   shipping_limit_date  112650 non-null  datetime64[ns]\n",
      " 4   price                112650 non-null  float64       \n",
      " 5   freight_value        112650 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 5.2+ MB\n",
      "\n",
      "Successfully saved cleaned minimal order items data to: archive/cleaned_order_items_minimal.csv\n",
      "Original shape: (32951, 9)\n",
      "\n",
      "Missing 'product_category_name' values (Before): 610\n",
      "Filled NaN values with 'unknown'.\n",
      "Missing 'product_category_name' values (After): 0\n",
      "\n",
      "Head of the cleaned, minimal products DataFrame:\n",
      "                         product_id  product_category_name\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria\n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes\n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer\n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes\n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas\n",
      "\n",
      "Successfully saved cleaned minimal product data to: archive/cleaned_products_minimal.csv\n",
      "Original shape: (99441, 5)\n",
      "\n",
      "Head of the minimal customer DataFrame:\n",
      "                        customer_id                customer_unique_id\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0\n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3\n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e\n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c\n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066\n",
      "\n",
      "Successfully saved minimal customer data to: archive/customers_minimal.csv\n",
      "\n",
      "--- All cleaning tasks complete. ---\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Clean and Minimize Orders DataFrame ---\n",
    "try:\n",
    "    print(f\"Original shape: {orders_df.shape}\")\n",
    "\n",
    "    # Investigate 'order_status'\n",
    "    print(\"\\n'order_status' counts:\")\n",
    "    print(orders_df['order_status'].value_counts(dropna=False))\n",
    "\n",
    "    # Filter for 'delivered' orders\n",
    "    delivered_orders_df = orders_df[orders_df['order_status'] == 'delivered'].copy()\n",
    "    print(f\"\\nFiltered for 'delivered' status. New shape: {delivered_orders_df.shape}\")\n",
    "\n",
    "    # Convert Timestamps\n",
    "    print(\"\\nConverting timestamp columns...\")\n",
    "    timestamp_cols = [\n",
    "        'order_purchase_timestamp',\n",
    "        'order_approved_at',\n",
    "        'order_delivered_carrier_date',\n",
    "        'order_delivered_customer_date',\n",
    "        'order_estimated_delivery_date'\n",
    "    ]\n",
    "    for col in timestamp_cols:\n",
    "        delivered_orders_df[col] = pd.to_datetime(delivered_orders_df[col])\n",
    "    \n",
    "    # --- Create a Minimal DataFrame for Merging ---\n",
    "    cleaned_orders_minimal = delivered_orders_df[['order_id','customer_id','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date']]\n",
    "\n",
    "    # Verify changes\n",
    "    print(\"\\nVerifying 'cleaned_orders_minimal' Dtypes:\")\n",
    "    cleaned_orders_minimal.info()\n",
    "\n",
    "    # Save the cleaned file\n",
    "    output_file_orders = f'{DATA_DIR}/cleaned_orders_minimal.csv'\n",
    "    cleaned_orders_minimal.to_csv(output_file_orders, index=False)\n",
    "    print(f\"\\nSuccessfully saved cleaned minimal orders data to: {output_file_orders}\")\n",
    "    dataframes[\"Orders\"] = cleaned_orders_minimal  # Update the reference\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "\n",
    "# --- 2. Clean and Minimize Reviews DataFrame ---\n",
    "print(\"\\n--- Processing: Reviews DataFrame ---\")\n",
    "try:\n",
    "    print(f\"Original shape: {reviews_df.shape}\")\n",
    "    print(\"Converting timestamp columns...\")\n",
    "\n",
    "    review_ts_cols = ['review_creation_date', 'review_answer_timestamp']\n",
    "    for col in review_ts_cols:\n",
    "        reviews_df[col] = pd.to_datetime(reviews_df[col])\n",
    "\n",
    "    cleaned_reviews_minimal = reviews_df[['order_id','review_score', 'review_comment_message']]\n",
    "    \n",
    "    # Verify changes\n",
    "    print(\"\\nVerifying 'cleaned_reviewes_minimal' Dtypes:\")\n",
    "    cleaned_reviews_minimal.info()\n",
    "\n",
    "    # Save the cleaned file\n",
    "    output_file_reviews = f'{DATA_DIR}/cleaned_reviews_minimal.csv'\n",
    "    cleaned_reviews_minimal.to_csv(output_file_reviews, index=False)\n",
    "    print(f\"\\nSuccessfully saved cleaned minimal reviews data to: {output_file_reviews}\")\n",
    "    dataframes[\"Reviews\"] = cleaned_reviews_minimal  # Update the reference\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "\n",
    "# --- 3. Clean and Minimize Order Items DataFrame ---\n",
    "print(\"\\n--- Processing: Order Items DataFrame ---\")\n",
    "try:\n",
    "    print(f\"Original shape: {order_items_df.shape}\")\n",
    "    print(\"Converting 'shipping_limit_date' to datetime object...\")\n",
    "    \n",
    "    order_items_df['shipping_limit_date'] = pd.to_datetime(order_items_df['shipping_limit_date'])\n",
    "\n",
    "    cleaned_order_items_minimal = order_items_df[['order_id','product_id','seller_id','shipping_limit_date','price','freight_value']]\n",
    "    \n",
    "    # Verify changes\n",
    "    print(\"\\nVerifying 'cleaned_order_items_minimal' Dtypes:\")\n",
    "    cleaned_order_items_minimal.info()\n",
    "\n",
    "    # Save the cleaned file\n",
    "    output_file_items = f'{DATA_DIR}/cleaned_order_items_minimal.csv'\n",
    "    cleaned_order_items_minimal.to_csv(output_file_items, index=False)\n",
    "    print(f\"\\nSuccessfully saved cleaned minimal order items data to: {output_file_items}\")\n",
    "    dataframes[\"Order Items\"] = cleaned_order_items_minimal  # Update the reference\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "# --- 4. Clean and Minimize Products DataFrame ---\n",
    "try:\n",
    "    print(f\"Original shape: {products_df.shape}\")\n",
    "\n",
    "    # --- 1. Inspect Missing Values (Before) ---\n",
    "    missing_count = products_df['product_category_name'].isnull().sum()\n",
    "    print(f\"\\nMissing 'product_category_name' values (Before): {missing_count}\")\n",
    "\n",
    "    # --- 2. Clean the Column ---\n",
    "    # Fill NaN values with the string 'unknown'\n",
    "    products_df['product_category_name'] = products_df['product_category_name'].fillna('unknown')\n",
    "    print(\"Filled NaN values with 'unknown'.\")\n",
    "\n",
    "    # --- 3. Verify the Cleaning (After) ---\n",
    "    missing_count_after = products_df['product_category_name'].isnull().sum()\n",
    "    print(f\"Missing 'product_category_name' values (After): {missing_count_after}\")\n",
    "\n",
    "    # --- 4. Create a Minimal DataFrame for Merging ---\n",
    "    cleaned_products_minimal = products_df[['product_id', 'product_category_name']]\n",
    "    \n",
    "    print(\"\\nHead of the cleaned, minimal products DataFrame:\")\n",
    "    print(cleaned_products_minimal.head())\n",
    "\n",
    "    # --- 5. Save the Cleaned File ---\n",
    "    output_file = f'{DATA_DIR}/cleaned_products_minimal.csv'\n",
    "    cleaned_products_minimal.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccessfully saved cleaned minimal product data to: {output_file}\")\n",
    "    dataframes[\"Products\"] = cleaned_products_minimal  # Update the reference\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "# --- 5. Minimize Customer DataFrame ---\n",
    "try:\n",
    "    print(f\"Original shape: {customers_df.shape}\")\n",
    "\n",
    "    # --- 1. Create a Minimal DataFrame for Merging ---\n",
    "    customers_minimal = customers_df[['customer_id', 'customer_unique_id']]\n",
    "    \n",
    "    print(\"\\nHead of the minimal customer DataFrame:\")\n",
    "    print(customers_minimal.head())\n",
    "\n",
    "    # --- 2. Save the Minimal File ---\n",
    "    output_file = f'{DATA_DIR}/customers_minimal.csv'\n",
    "    customers_minimal.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccessfully saved minimal customer data to: {output_file}\")\n",
    "    dataframes[\"Customers\"] = customers_minimal  # Update the reference\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "print(\"\\n--- All cleaning tasks complete. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75124498",
   "metadata": {},
   "source": [
    "Now that the dataframes are cleaned and minimized, it is time to calculate features and assemble the final customer centric dataframe. We'll start by calculating the recency, frequency, and tenure features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d675f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join customers and orders to link customer_unique_id to order_id\n",
    "dataframes[\"Customer Orders\"] = pd.merge(\n",
    "    dataframes[\"Customers\"],  # Has customer_id, customer_unique_id\n",
    "    dataframes[\"Orders\"],     # Has customer_id, order_id, and all dates\n",
    "    on='customer_id'\n",
    ")\n",
    "\n",
    "# We need a \"snapshot date\" to calculate recency (1 day after the last purchase)\n",
    "snapshot_date = dataframes[\"Customer Orders\"]['order_purchase_timestamp'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Group by customer and aggregate\n",
    "rft_features = dataframes[\"Customer Orders\"].groupby('customer_unique_id').agg(\n",
    "    last_purchase=('order_purchase_timestamp', 'max'),\n",
    "    Frequency=('order_id', 'nunique'),\n",
    "    first_purchase=('order_purchase_timestamp', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate Recency and Tenure in days\n",
    "rft_features['Recency'] = (snapshot_date - rft_features['last_purchase']).dt.days\n",
    "rft_features['Tenure'] = (snapshot_date - rft_features['first_purchase']).dt.days\n",
    "\n",
    "# This is our starting point for the final DataFrame\n",
    "dataframes[\"Customer Centric\"] = rft_features[['customer_unique_id', 'Recency', 'Frequency', 'Tenure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f29478",
   "metadata": {},
   "source": [
    "Now moving on to the monetary and payment features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3581a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link payments to the customer/order master\n",
    "dataframes[\"Merged Payments\"] = pd.merge(\n",
    "    dataframes[\"Customer Orders\"][['customer_unique_id', 'order_id']],\n",
    "    dataframes[\"Order Payments\"],\n",
    "    on='order_id'\n",
    ")\n",
    "\n",
    "# 1. Aggregate basic payment features\n",
    "payment_features = dataframes[\"Merged Payments\"].groupby('customer_unique_id').agg(\n",
    "    Monetary=('payment_value', 'sum'),\n",
    "    avg_payment_installments=('payment_installments', 'mean'),\n",
    "    preferred_payment_method=('payment_type', lambda x: x.mode()[0]) # Get the most frequent\n",
    ").reset_index()\n",
    "\n",
    "# 2. Calculate Payment Complexity (multi-step)\n",
    "# Find the max sequential number for *each order*\n",
    "order_complexity = dataframes[\"Merged Payments\"].groupby(['customer_unique_id', 'order_id']) \\\n",
    "                                  .agg(max_sequential=('payment_sequential', 'max')) \\\n",
    "                                  .reset_index()\n",
    "# Now, find the average complexity *per customer*\n",
    "customer_complexity = order_complexity.groupby('customer_unique_id') \\\n",
    "                                      .agg(avg_payment_complexity=('max_sequential', 'mean')) \\\n",
    "                                      .reset_index()\n",
    "\n",
    "# --- Merge this group into the main DataFrame ---\n",
    "dataframes[\"Customer Centric\"] = pd.merge(dataframes[\"Customer Centric\"], payment_features, on='customer_unique_id', how='left')\n",
    "dataframes[\"Customer Centric\"] = pd.merge(dataframes[\"Customer Centric\"], customer_complexity, on='customer_unique_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f8d6e",
   "metadata": {},
   "source": [
    "Next review features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9f30956",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_merged = pd.merge(\n",
    "    dataframes[\"Customer Orders\"][['customer_unique_id', 'order_id']],\n",
    "    reviews_df,\n",
    "    on='order_id'\n",
    ")\n",
    "\n",
    "# Aggregate review features\n",
    "review_features = reviews_merged.groupby('customer_unique_id').agg(\n",
    "    avg_review_score=('review_score', 'mean'),\n",
    "    # .mean() on a boolean (notnull()) gives the ratio/rate\n",
    "    review_engagement_rate=('review_comment_message', lambda x: x.notnull().mean()) \n",
    ").reset_index()\n",
    "\n",
    "# --- Merge this group into the main DataFrame ---\n",
    "dataframes[\"Customer Centric\"] = pd.merge(dataframes[\"Customer Centric\"], review_features, on='customer_unique_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4ece6",
   "metadata": {},
   "source": [
    "Item, product, and seller features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41bb1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link items to customers/orders\n",
    "items_merged = pd.merge(\n",
    "    dataframes[\"Customer Orders\"][['customer_unique_id', 'order_id']],\n",
    "    dataframes[\"Order Items\"],\n",
    "    on='order_id'\n",
    ")\n",
    "# Now link to products to get the category\n",
    "products_merged = pd.merge(\n",
    "    items_merged,\n",
    "    products_df,\n",
    "    on='product_id'\n",
    ")\n",
    "\n",
    "# Aggregate features from this combined table\n",
    "item_features = products_merged.groupby('customer_unique_id').agg(\n",
    "    total_freight_value=('freight_value', 'sum'), # We'll calculate avg cost later\n",
    "    unique_product_categories=('product_category_name', 'nunique'),\n",
    "    unique_sellers=('seller_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# --- Merge this group into the main DataFrame ---\n",
    "dataframes[\"Customer Centric\"] = pd.merge(dataframes[\"Customer Centric\"], item_features, on='customer_unique_id', how='left')\n",
    "\n",
    "# Create the Average Shipping Cost (using total_freight and Frequency)\n",
    "dataframes[\"Customer Centric\"]['avg_shipping_cost'] = (\n",
    "    dataframes[\"Customer Centric\"].pop('total_freight_value') / dataframes[\"Customer Centric\"]['Frequency']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa16f8",
   "metadata": {},
   "source": [
    "Gap time features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a146b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to link items to get the shipping_limit_date for each order\n",
    "gaps_merged = pd.merge(\n",
    "    dataframes[\"Customer Orders\"],\n",
    "    dataframes[\"Order Items\"][['order_id', 'shipping_limit_date']],\n",
    "    on='order_id'\n",
    ")\n",
    "\n",
    "# De-duplicate: An order with 3 items will have 3 rows. We only need one row per order.\n",
    "# We'll take the LAST shipping_limit_date as the deadline for the whole order.\n",
    "gaps_df_orders = gaps_merged.groupby('order_id').agg({\n",
    "    'customer_unique_id': 'first',\n",
    "    'order_purchase_timestamp': 'first',\n",
    "    'order_approved_at': 'first',\n",
    "    'order_delivered_carrier_date': 'first',\n",
    "    'order_delivered_customer_date': 'first',\n",
    "    'order_estimated_delivery_date': 'first',\n",
    "    'shipping_limit_date': 'max' # Use the last deadline\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate all gaps in hours (or days)\n",
    "gaps_df_orders['avg_payment_approval_time'] = (gaps_df_orders['order_approved_at'] - gaps_df_orders['order_purchase_timestamp']).dt.total_seconds() / 3600\n",
    "gaps_df_orders['avg_delivery_vs_estimate'] = (gaps_df_orders['order_estimated_delivery_date'] - gaps_df_orders['order_delivered_customer_date']).dt.total_seconds() / (24 * 3600)\n",
    "gaps_df_orders['avg_carrier_shipping_time'] = (gaps_df_orders['order_delivered_customer_date'] - gaps_df_orders['order_delivered_carrier_date']).dt.total_seconds() / (24 * 3600)\n",
    "gaps_df_orders['avg_shipping_vs_deadline'] = (gaps_df_orders['shipping_limit_date'] - gaps_df_orders['order_delivered_carrier_date']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Now, average these order-level gaps for each customer\n",
    "gap_features = gaps_df_orders.groupby('customer_unique_id')[[\n",
    "    'avg_payment_approval_time', 'avg_delivery_vs_estimate', 'avg_carrier_shipping_time',\n",
    "    'avg_shipping_vs_deadline'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# --- Merge this final group ---\n",
    "dataframes[\"Customer Centric\"] = pd.merge(dataframes[\"Customer Centric\"], gap_features, on='customer_unique_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d0696",
   "metadata": {},
   "source": [
    "And we're done! Time to clean any NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "768000dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs before cleaning:\n",
      "customer_unique_id             0\n",
      "Recency                        0\n",
      "Frequency                      0\n",
      "Tenure                         0\n",
      "Monetary                       1\n",
      "avg_payment_installments       1\n",
      "preferred_payment_method       1\n",
      "avg_payment_complexity         1\n",
      "avg_review_score             603\n",
      "review_engagement_rate       603\n",
      "unique_product_categories      0\n",
      "unique_sellers                 0\n",
      "avg_shipping_cost              0\n",
      "avg_payment_approval_time     13\n",
      "avg_delivery_vs_estimate       8\n",
      "avg_carrier_shipping_time      9\n",
      "avg_shipping_vs_deadline       2\n",
      "dtype: int64\n",
      "NaNs after cleaning:\n",
      "customer_unique_id           0\n",
      "Recency                      0\n",
      "Frequency                    0\n",
      "Tenure                       0\n",
      "Monetary                     0\n",
      "avg_payment_installments     0\n",
      "preferred_payment_method     0\n",
      "avg_payment_complexity       0\n",
      "avg_review_score             0\n",
      "review_engagement_rate       0\n",
      "unique_product_categories    0\n",
      "unique_sellers               0\n",
      "avg_shipping_cost            0\n",
      "avg_payment_approval_time    0\n",
      "avg_delivery_vs_estimate     0\n",
      "avg_carrier_shipping_time    0\n",
      "avg_shipping_vs_deadline     0\n",
      "dtype: int64\n",
      "--- Final Customer-Centric DataFrame Assembled ---\n",
      "                 customer_unique_id  Recency  Frequency  Tenure  Monetary  \\\n",
      "0  0000366f3b9a7992bf8c76cfdf3221e2      112          1     112    141.90   \n",
      "1  0000b849f77a49e4a4ce2b2a4ca5be3f      115          1     115     27.19   \n",
      "2  0000f46a3911fa3c0805444483337064      537          1     537     86.22   \n",
      "3  0000f6ccb0745a6a4b88665a16c9f078      321          1     321     43.62   \n",
      "4  0004aac84e0df4da2b147fca70cf8255      288          1     288    196.89   \n",
      "\n",
      "   avg_payment_installments preferred_payment_method  avg_payment_complexity  \\\n",
      "0                       8.0              credit_card                     1.0   \n",
      "1                       1.0              credit_card                     1.0   \n",
      "2                       8.0              credit_card                     1.0   \n",
      "3                       4.0              credit_card                     1.0   \n",
      "4                       6.0              credit_card                     1.0   \n",
      "\n",
      "   avg_review_score  review_engagement_rate  unique_product_categories  \\\n",
      "0               5.0                     1.0                          1   \n",
      "1               4.0                     0.0                          1   \n",
      "2               3.0                     0.0                          1   \n",
      "3               4.0                     1.0                          1   \n",
      "4               5.0                     0.0                          1   \n",
      "\n",
      "   unique_sellers  avg_shipping_cost  avg_payment_approval_time  \\\n",
      "0               1              12.00                   0.247500   \n",
      "1               1               8.29                   7.238056   \n",
      "2               1              17.22                   0.000000   \n",
      "3               1              17.63                   0.326667   \n",
      "4               1              16.89                   0.352778   \n",
      "\n",
      "   avg_delivery_vs_estimate  avg_carrier_shipping_time  \\\n",
      "0                  4.132905                   4.521262   \n",
      "1                  4.248125                   1.239375   \n",
      "2                  1.389734                  23.069641   \n",
      "3                 11.108970                  19.051921   \n",
      "4                  7.035463                  11.136644   \n",
      "\n",
      "   avg_shipping_vs_deadline  \n",
      "0                  3.120347  \n",
      "1                  2.235104  \n",
      "2                  2.337882  \n",
      "3                  5.070116  \n",
      "4                  6.010208  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 93357 entries, 0 to 93357\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   customer_unique_id         93357 non-null  object \n",
      " 1   Recency                    93357 non-null  int64  \n",
      " 2   Frequency                  93357 non-null  int64  \n",
      " 3   Tenure                     93357 non-null  int64  \n",
      " 4   Monetary                   93357 non-null  float64\n",
      " 5   avg_payment_installments   93357 non-null  float64\n",
      " 6   preferred_payment_method   93357 non-null  object \n",
      " 7   avg_payment_complexity     93357 non-null  float64\n",
      " 8   avg_review_score           93357 non-null  float64\n",
      " 9   review_engagement_rate     93357 non-null  float64\n",
      " 10  unique_product_categories  93357 non-null  int64  \n",
      " 11  unique_sellers             93357 non-null  int64  \n",
      " 12  avg_shipping_cost          93357 non-null  float64\n",
      " 13  avg_payment_approval_time  93357 non-null  float64\n",
      " 14  avg_delivery_vs_estimate   93357 non-null  float64\n",
      " 15  avg_carrier_shipping_time  93357 non-null  float64\n",
      " 16  avg_shipping_vs_deadline   93357 non-null  float64\n",
      "dtypes: float64(10), int64(5), object(2)\n",
      "memory usage: 12.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "print(\"NaNs before cleaning:\")\n",
    "print(dataframes[\"Customer Centric\"].isnull().sum())\n",
    "\n",
    "# Fill NaNs with logical defaults\n",
    "dataframes[\"Customer Centric\"]['avg_review_score'] = dataframes[\"Customer Centric\"]['avg_review_score'].fillna(\n",
    "    dataframes[\"Customer Centric\"]['avg_review_score'].mean() # Impute with the mean score\n",
    ")\n",
    "dataframes[\"Customer Centric\"]['review_engagement_rate'] = dataframes[\"Customer Centric\"]['review_engagement_rate'].fillna(0) # 0% engagement\n",
    "dataframes[\"Customer Centric\"]['avg_payment_complexity'] = dataframes[\"Customer Centric\"]['avg_payment_complexity'].fillna(1) # Default to 1\n",
    "\n",
    "# Drop customer with no monetary value (never paid)\n",
    "dataframes[\"Customer Centric\"].dropna(subset=['Monetary'], inplace=True)\n",
    "\n",
    "# Handle the 2-13 gap time NaNs\n",
    "# Impute with the mean time for each\n",
    "for col in ['avg_payment_approval_time', 'avg_delivery_vs_estimate', \n",
    "            'avg_carrier_shipping_time', 'avg_shipping_vs_deadline']:\n",
    "    dataframes[\"Customer Centric\"][col] = dataframes[\"Customer Centric\"][col].fillna(\n",
    "        dataframes[\"Customer Centric\"][col].mean()\n",
    "    )\n",
    "\n",
    "print(\"NaNs after cleaning:\")\n",
    "print(dataframes[\"Customer Centric\"].isnull().sum())\n",
    "\n",
    "# Save the final file\n",
    "dataframes[\"Customer Centric\"].to_csv('customer_centric_features.csv', index=False)\n",
    "\n",
    "print(\"--- Final Customer-Centric DataFrame Assembled ---\")\n",
    "print(dataframes[\"Customer Centric\"].head())\n",
    "print(dataframes[\"Customer Centric\"].info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
